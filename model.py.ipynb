{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT=28\n",
    "WIDTH=28\n",
    "NCLASSES=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(img, mode, hparams):\n",
    "  X = tf.reshape(img,[-1,HEIGHT*WIDTH]) #flatten\n",
    "  ylogits = tf.layers.dense(X,NCLASSES,activation=None)\n",
    "  return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(img, mode, hparams):\n",
    "  X = tf.reshape(img, [-1, HEIGHT*WIDTH]) #flatten\n",
    "  h1 = tf.layers.dense(X, 300, activation=tf.nn.relu)\n",
    "  h2 = tf.layers.dense(h1,100, activation=tf.nn.relu)\n",
    "  h3 = tf.layers.dense(h2, 30, activation=tf.nn.relu)\n",
    "  ylogits = tf.layers.dense(h3, NCLASSES, activation=None)\n",
    "  return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_dropout_model(img, mode, hparams):\n",
    "  dprob = hparams.get('dprob', 0.1)\n",
    "\n",
    "  X = tf.reshape(img, [-1, HEIGHT*WIDTH]) #flatten\n",
    "  h1 = tf.layers.dense(X, 300, activation=tf.nn.relu)\n",
    "  h2 = tf.layers.dense(h1,100, activation=tf.nn.relu)\n",
    "  h3 = tf.layers.dense(h2, 30, activation=tf.nn.relu)\n",
    "  h3d = tf.layers.dropout(h3, rate=dprob, training=(\n",
    "      mode == tf.estimator.ModeKeys.TRAIN)) #only dropout when training\n",
    "  ylogits = tf.layers.dense(h3d, NCLASSES, activation=None)\n",
    "  return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(img, mode, hparams):\n",
    "  ksize1 = hparams.get('ksize1', 5)\n",
    "  ksize2 = hparams.get('ksize2', 5)\n",
    "  nfil1 = hparams.get('nfil1', 10)\n",
    "  nfil2 = hparams.get('nfil2', 20)\n",
    "  dprob = hparams.get('dprob', 0.25)\n",
    "  \n",
    "  c1 = tf.layers.conv2d(img, filters=nfil1,\n",
    "                          kernel_size=ksize1, strides=1, # ?x28x28x10\n",
    "                          padding='same', activation=tf.nn.relu)\n",
    "  p1 = tf.layers.max_pooling2d(c1,pool_size=2, strides=2) # ?x14x14x10\n",
    "  c2 = tf.layers.conv2d(p1, filters=nfil2,\n",
    "                          kernel_size=ksize2, strides=1, \n",
    "                          padding='same', activation=tf.nn.relu)\n",
    "  p2 = tf.layers.max_pooling2d(c2,pool_size=2, strides=2) # ?x7x7x20\n",
    "  \n",
    "  outlen = p2.shape[1]*p2.shape[2]*p2.shape[3] #980\n",
    "  p2flat = tf.reshape(p2, [-1, outlen]) # flattened\n",
    "\n",
    "  #apply batch normalization\n",
    "  if hparams['batch_norm']:\n",
    "    h3 = tf.layers.dense(p2flat, 300, activation=None)\n",
    "    h3 = tf.layers.batch_normalization(\n",
    "        h3, training=(mode == tf.estimator.ModeKeys.TRAIN)) #only batchnorm when training\n",
    "    h3 = tf.nn.relu(h3)\n",
    "  else:  \n",
    "    h3 = tf.layers.dense(p2flat, 300, activation=tf.nn.relu)\n",
    "  \n",
    "  #apply dropout\n",
    "  h3d = tf.layers.dropout(h3, rate=dprob, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "  ylogits = tf.layers.dense(h3d, NCLASSES, activation=None)\n",
    "  \n",
    "  #apply batch normalization once more\n",
    "  if hparams['batch_norm']:\n",
    "     ylogits = tf.layers.batch_normalization(\n",
    "         ylogits, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "  return ylogits, NCLASSES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    #input will be rank 3\n",
    "    feature_placeholders = {\n",
    "        'image': tf.placeholder(tf.float32, [None, HEIGHT, WIDTH])}\n",
    "    #but model function requires rank 4\n",
    "    features = {\n",
    "        'image': tf.expand_dims(feature_placeholders['image'],-1)} \n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_classifier(features, labels, mode, params):\n",
    "  model_functions = {\n",
    "      'linear':linear_model,\n",
    "      'dnn':dnn_model,\n",
    "      'dnn_dropout':dnn_dropout_model,\n",
    "      'cnn':cnn_model}\n",
    "  model_function = model_functions[params['model']]  \n",
    "  ylogits, nclasses = model_function(features['image'], mode, params)\n",
    "\n",
    "  probabilities = tf.nn.softmax(ylogits)\n",
    "  classes = tf.cast(tf.argmax(probabilities, 1), tf.uint8)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            logits=ylogits, labels=labels))\n",
    "    evalmetrics = {'accuracy': tf.metrics.accuracy(classes, tf.argmax(labels, 1))}\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      # this is needed for batch normalization, but has no effect otherwise\n",
    "      update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "      with tf.control_dependencies(update_ops):\n",
    "         train_op = tf.contrib.layers.optimize_loss(\n",
    "             loss, \n",
    "             tf.train.get_global_step(),\n",
    "             learning_rate=params['learning_rate'], \n",
    "             optimizer=\"Adam\")\n",
    "    else:\n",
    "      train_op = None\n",
    "  else:\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    evalmetrics = None\n",
    " \n",
    "  return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions={\"probabilities\": probabilities, \"classes\": classes},\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=evalmetrics,\n",
    "        export_outputs={'classes':tf.estimator.export.PredictOutput(\n",
    "            {\"probabilities\": probabilities, \"classes\": classes})}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, hparams):\n",
    "  EVAL_INTERVAL = 60\n",
    "\n",
    "  mnist = input_data.read_data_sets('mnist/data', one_hot=True, reshape=False)\n",
    "\n",
    "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'image':mnist.train.images},\n",
    "    y=mnist.train.labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True,\n",
    "    queue_capacity=5000\n",
    "  )\n",
    "\n",
    "  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'image':mnist.test.images},\n",
    "    y=mnist.test.labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=1,\n",
    "    shuffle=False,\n",
    "    queue_capacity=5000\n",
    "  )\n",
    "  estimator = tf.estimator.Estimator(model_fn = image_classifier,\n",
    "                                     params = hparams,\n",
    "                                     config=tf.estimator.RunConfig(\n",
    "                                         save_checkpoints_secs = EVAL_INTERVAL),\n",
    "                                     model_dir = output_dir)\n",
    "  train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn,\n",
    "                                    max_steps = hparams['train_steps'])\n",
    "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "  eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn,\n",
    "                                  steps = None,\n",
    "                                  exporters = exporter,\n",
    "                                  throttle_secs = EVAL_INTERVAL)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
