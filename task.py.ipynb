{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example implementation of image model in TensorFlow \n",
    "that can be trained and deployed on Cloud ML Engine\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from . import model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  # Input Arguments\n",
    "  parser.add_argument(\n",
    "      '--train_batch_size',\n",
    "      help='Batch size for training steps',\n",
    "      type=int,\n",
    "      default=100)\n",
    "  parser.add_argument(\n",
    "      '--learning_rate',\n",
    "      help='Initial learning rate for training',\n",
    "      type=float,\n",
    "      default=0.01)\n",
    "  parser.add_argument(\n",
    "      '--train_steps',\n",
    "      help=\"\"\"\\\n",
    "      Steps to run the training job for. A step is one batch-size,\\\n",
    "      \"\"\",\n",
    "      type=int,\n",
    "      default=0)\n",
    "  parser.add_argument(\n",
    "      '--output_dir',\n",
    "      help='GCS location to write checkpoints and export models',\n",
    "      required=True)\n",
    "  #generate list of model functions to print in help message\n",
    "  model_names = [name.replace('_model','') \\\n",
    "                   for name in dir(model) \\\n",
    "                     if name.endswith('_model')]\n",
    "  parser.add_argument(\n",
    "      '--model',\n",
    "      help='Type of model. Supported types are {}'.format(model_names),\n",
    "      default='linear')\n",
    "  parser.add_argument(\n",
    "      '--job-dir',\n",
    "      help='this model ignores this field, but it is required by gcloud',\n",
    "      default='junk')\n",
    "\n",
    "  # optional hyperparameters used by cnn\n",
    "  parser.add_argument(\n",
    "      '--ksize1', \n",
    "      help='kernel size of first layer for CNN', \n",
    "      type=int, \n",
    "      default=5)\n",
    "  parser.add_argument(\n",
    "      '--ksize2', \n",
    "      help='kernel size of second layer for CNN', \n",
    "      type=int, \n",
    "      default=5)\n",
    "  parser.add_argument(\n",
    "      '--nfil1', \n",
    "      help='number of filters in first layer for CNN', \n",
    "      type=int, \n",
    "      default=10)\n",
    "  parser.add_argument(\n",
    "      '--nfil2', \n",
    "      help='number of filters in second layer for CNN', \n",
    "      type=int, \n",
    "      default=20)\n",
    "  parser.add_argument(\n",
    "      '--dprob', \n",
    "      help='dropout probability for CNN', \n",
    "      type=float, \n",
    "      default=0.25)\n",
    "  parser.add_argument(\n",
    "      '--batch_norm', \n",
    "      help='if specified, do batch_norm for CNN', \n",
    "      dest='batch_norm', \n",
    "      action='store_true')\n",
    "  parser.set_defaults(batch_norm=False)\n",
    "\n",
    "  args = parser.parse_args()\n",
    "  hparams = args.__dict__\n",
    "  \n",
    "  # unused args provided by service\n",
    "  hparams.pop('job_dir', None)\n",
    "  hparams.pop('job-dir', None)\n",
    "\n",
    "  output_dir = hparams.pop('output_dir')\n",
    "  # Append trial_id to path so hptuning jobs don't overwrite eachother\n",
    "  output_dir = os.path.join(\n",
    "      output_dir,\n",
    "      json.loads(\n",
    "          os.environ.get('TF_CONFIG', '{}')\n",
    "      ).get('task', {}).get('trial', '')\n",
    "  )\n",
    "\n",
    "  # calculate train_steps if not provided\n",
    "  if hparams['train_steps'] < 1:\n",
    "     # 10,000 steps at batch_size of 512\n",
    "     hparams['train_steps'] = (10000 * 512) // hparams['train_batch_size']\n",
    "     print(\"Training for {} steps\".format(hparams['train_steps']))\n",
    "  \n",
    "  \n",
    "  # Run the training job\n",
    "  model.train_and_evaluate(output_dir, hparams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
